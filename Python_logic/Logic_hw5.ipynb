{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import mapreduce as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'end_station_id': '423', 'gender': '2', 'bikeid': '17131', 'start_station_latitude': '40.75044999', 'end_station_name': 'W 54 St & 9 Ave', 'cartodb_id': '1', 'start_station_name': '8 Ave & W 31 St', 'start_station_id': '521', 'start_station_longitude': '-73.99481051', 'usertype': 'Subscriber', 'stoptime': '2015-02-01 00:14:00+00', 'end_station_longitude': '-73.98690506', 'starttime': '2015-02-01 00:00:00+00', 'end_station_latitude': '40.76584941', 'tripduration': '801', 'the_geom': '', 'birth_year': '1978'}\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/citibike.csv\"\n",
    "with open (filename,\"r\") as fi:\n",
    "    reader = csv.DictReader(fi)\n",
    "    for ride in reader:\n",
    "        print ride\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '', '801', '2015-02-01 00:00:00+00', '2015-02-01 00:14:00+00', '521', '8 Ave & W 31 St', '40.75044999', '-73.99481051', '423', 'W 54 St & 9 Ave', '40.76584941', '-73.98690506', '17131', 'Subscriber', '1978', '2']\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/citibike_no_headers.csv\"\n",
    "with open (filename,\"r\") as fi:\n",
    "    reader = csv.reader(fi)\n",
    "    for ride in reader:\n",
    "        print ride\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, {1: 172, 2: 336, 3: 572, 4: 799, 5: 867, 6: 854, 7: 826, 8: 706, 9: 671, 10: 574, 11: 512, 12: 477, 13: 365, 14: 317, 15: 252, 16: 217, 17: 170, 18: 150, 19: 126, 20: 115, 21: 97, 22: 90, 23: 82, 24: 86, 25: 54, 26: 53, 27: 33, 28: 59, 29: 47, 30: 26, 31: 23, 32: 31, 33: 19, 34: 22, 35: 15, 36: 23, 37: 12, 38: 8, 39: 10, 40: 6, 41: 8, 42: 10, 43: 4, 44: 4, 45: 2, 46: 5, 47: 2, 48: 1, 49: 7, 50: 2, 51: 4, 52: 1, 53: 4, 54: 2, 55: 3, 56: 1, 57: 2, 58: 2, 60: 1, 61: 1, 62: 3, 63: 1, 66: 1, 523: 1, 69: 2, 70: 2, 72: 2, 585: 1, 74: 1, 587: 1, 76: 1, 84: 1, 87: 3, 88: 1, 92: 1, 94: 1, 95: 1, 96: 1, 98: 2, 99: 1, 106: 1, 627: 1, 116: 1, 118: 1, 120: 1, 127: 1, 128: 1, 131: 1, 138: 1, 139: 2, 159: 1, 165: 1, 166: 1, 517: 1, 185: 1, 188: 1, 713: 1, 716: 1, 224: 1, 519: 1, 248: 1, 254: 1, 520: 1, 294: 1, 295: 1, 322: 1, 353: 1, 363: 1, 364: 1, 232: 1, 441: 1}), (0, {1: 81, 2: 198, 3: 415, 4: 680, 5: 747, 6: 877, 7: 837, 8: 845, 9: 733, 10: 645, 11: 570, 12: 477, 13: 394, 14: 317, 15: 266, 16: 265, 17: 212, 18: 173, 19: 150, 20: 132, 21: 118, 22: 95, 23: 88, 24: 82, 25: 61, 26: 51, 27: 59, 28: 51, 29: 46, 30: 42, 31: 35, 32: 34, 33: 24, 34: 21, 35: 14, 36: 19, 37: 11, 38: 15, 39: 13, 40: 12, 41: 10, 42: 4, 43: 4, 44: 10, 45: 6, 46: 5, 47: 2, 48: 3, 49: 5, 51: 1, 52: 4, 55: 1, 57: 1, 58: 2, 59: 1, 60: 2, 61: 1, 62: 1, 63: 2, 66: 1, 67: 1, 75: 1, 77: 1, 79: 1, 84: 1, 89: 1, 91: 2, 92: 1, 96: 1, 103: 1, 109: 1, 110: 1, 133: 1, 156: 1, 159: 1, 163: 1, 177: 1, 543: 1, 214: 1, 219: 1, 288: 1, 304: 1, 327: 1, 341: 1, 370: 1, 375: 1, 503: 1, 504: 1}), (0, {1: 99, 2: 255, 3: 601, 4: 803, 5: 887, 6: 932, 7: 912, 8: 813, 9: 703, 10: 634, 11: 519, 12: 425, 13: 373, 14: 271, 15: 234, 16: 186, 17: 158, 18: 167, 19: 127, 20: 104, 21: 93, 22: 95, 23: 77, 24: 65, 25: 54, 26: 48, 27: 44, 28: 46, 29: 36, 30: 35, 31: 20, 32: 16, 33: 26, 34: 24, 35: 21, 36: 7, 37: 13, 38: 7, 39: 5, 40: 5, 41: 8, 42: 6, 43: 7, 44: 5, 45: 5, 46: 1, 47: 4, 560: 1, 50: 2, 51: 2, 52: 1, 53: 1, 56: 2, 59: 1, 151: 1, 64: 1, 65: 1, 48: 1, 71: 1, 72: 1, 141: 1, 84: 1, 86: 1, 100: 1, 161: 1, 109: 1, 370: 1, 119: 1}), (0, {1: 97, 2: 277, 3: 604, 4: 823, 5: 911, 6: 914, 7: 936, 8: 806, 9: 714, 10: 589, 11: 534, 12: 399, 13: 371, 14: 317, 15: 264, 16: 191, 17: 161, 18: 129, 19: 95, 20: 131, 21: 88, 22: 93, 23: 63, 24: 55, 25: 50, 26: 46, 27: 31, 28: 43, 29: 32, 30: 29, 31: 22, 32: 20, 33: 21, 34: 16, 35: 22, 36: 17, 37: 12, 38: 6, 39: 8, 40: 2, 41: 6, 42: 1, 43: 7, 44: 6, 45: 3, 46: 1, 47: 1, 48: 2, 49: 1, 50: 5, 51: 3, 286: 1, 54: 1, 137: 1, 57: 2, 58: 1, 60: 1, 61: 1, 62: 1, 65: 1, 66: 1, 68: 1, 71: 1, 75: 1, 433: 1, 142: 1, 90: 1, 698: 1, 98: 1, 99: 1, 145: 1, 196: 1, 295: 1, 111: 1, 370: 1}), (0, {1: 54, 2: 197, 3: 355, 4: 522, 5: 561, 6: 546, 7: 528, 8: 462, 9: 383, 10: 381, 11: 279, 12: 237, 13: 212, 14: 212, 15: 151, 16: 145, 17: 115, 18: 107, 19: 79, 20: 87, 21: 58, 22: 54, 23: 54, 24: 42, 25: 37, 26: 42, 27: 34, 28: 19, 29: 22, 30: 24, 31: 24, 32: 29, 33: 23, 34: 21, 35: 9, 36: 9, 37: 12, 38: 7, 39: 2, 40: 3, 169: 1, 42: 2, 43: 3, 44: 1, 45: 2, 46: 3, 47: 2, 48: 3, 53: 1, 51: 1, 180: 1, 309: 1, 310: 1, 393: 1, 56: 1, 57: 3, 186: 1, 59: 2, 60: 1, 61: 1, 62: 2, 133: 1, 64: 2, 65: 1, 66: 1, 67: 1, 69: 1, 55: 1, 716: 1, 77: 1, 79: 1, 179: 1, 87: 1, 89: 1, 91: 2, 58: 1, 99: 1, 105: 1, 113: 1, 117: 1, 246: 1, 41: 4, 260: 1, 124: 1})]\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/citibike_no_headers.csv\"\n",
    "def mapper(reader):\n",
    "    mins = {}\n",
    "    for row in reader:\n",
    "        items = row.strip('\\n').split(',')\n",
    "        trip_min = int(items[2])/60\n",
    "        mins[trip_min] = mins.get(trip_min,0)+1\n",
    "    yield (0,mins)\n",
    "\n",
    "with open (filename,\"r\") as fi:\n",
    "    lst_mins = list(mr.runPartition(fi,mapper, chunk_size=10000))\n",
    "print lst_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Median trip duration is 8 minutes\n"
     ]
    }
   ],
   "source": [
    "#2:\n",
    "\n",
    "def mapper(fi):\n",
    "    mins = {}#initializing an empty dictionary\n",
    "    for row in fi: #type(row)=str\n",
    "        items = row.strip('\\n').split(',')#type(items)=list\n",
    "        trip_min = int(items[2])/60 \n",
    "        mins[trip_min] = mins.get(trip_min,0)+1 \n",
    "        # mins[trip_min] is syntax for assigning value to key in dictionary corresponding to trip_min\n",
    "        #this calls up the existing value corresponding to key of trip_min, and adds 1 to it. if there is no value, it assigs 0, and adds one to it\n",
    "    yield (0,mins) #after all 10,000 rows are done, yields a tupule containing 0 and the dictionary\n",
    "    \n",
    "    #(because mr expects a key and a count, and will shuffle all the stuff corresponding to the same keys (which is all 5 chunks' dictionaries) together into a list)\n",
    "\n",
    "#4\n",
    "def addBins((bins,tot_count),one_chunk_of_min_dicts):\n",
    "    for (m,c) in one_chunk_of_min_dicts.iteritems():\n",
    "        bins[m] = bins.get(m,0)+c\n",
    "        tot_count +=c\n",
    "    return (bins, tot_count)\n",
    "\n",
    "#3\n",
    "def reducer((now_useless_zero, min_dicts_as_list)):\n",
    "    #Remember: reduce basically does: addBins( ({},0) , mins_as_list[0] )\n",
    "    #                      and then : addBins( returned(bins, tot_count) , mins_as_list[1] ) and so on for the next dictionaries\n",
    "    \n",
    "    (bins, total_count) = reduce(addBins, min_dicts_as_list, ({}, 0))\n",
    "    #the above 'bins' now contains a single dictionary, containing all the trip_durs and their frequency, as well as total count (=46200)\n",
    "    #We will use this number, below, to calculate the median trip_dur(in mins)\n",
    "    count = 0\n",
    "    for (m,c) in bins.iteritems():\n",
    "        count+=c\n",
    "        if count>total_count/2:\n",
    "            return m\n",
    "    return 0\n",
    "\n",
    "#1:\n",
    "filename = \"../data/citibike_no_headers.csv\"\n",
    "with open (filename,\"r\") as fi: #type(fi)='file'\n",
    "    med_tripdur = list(mr.runPartition(fi,mapper, reducer, chunk_size=10000))#46,200 rows = 5 chunks\n",
    "print \"The Median trip duration is {} minutes\" .format(med_tripdur[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
